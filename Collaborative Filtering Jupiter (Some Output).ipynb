{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work done by:\n",
    "Nuno Pedrosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "from pyspark.mllib.recommendation import MatrixFactorizationModel\n",
    "import pyspark.sql.functions as F\n",
    "from math import sqrt\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conf = SparkConf()\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master('local[*]') \\\n",
    "    .config(\"spark.driver.memory\", \"15g\") \\\n",
    "    .appName(\"MovieLens CF\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading MovieLens dataset. Movies_df is used to ralationate the movieID with it' name. Ratings_df is has the score given by a user to a certain movie, it has the key information of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Movies_df = spark.read.csv(\"ml-latest-small/movies.csv\",header=True)\n",
    "Ratings_df = spark.read.csv(\"ml-latest-small/ratings.csv\",header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n",
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "|      6|         Heat (1995)|Action|Crime|Thri...|\n",
      "|      7|      Sabrina (1995)|      Comedy|Romance|\n",
      "|      8| Tom and Huck (1995)|  Adventure|Children|\n",
      "|      9| Sudden Death (1995)|              Action|\n",
      "|     10|    GoldenEye (1995)|Action|Adventure|...|\n",
      "|     11|American Presiden...|Comedy|Drama|Romance|\n",
      "|     12|Dracula: Dead and...|       Comedy|Horror|\n",
      "|     13|        Balto (1995)|Adventure|Animati...|\n",
      "|     14|        Nixon (1995)|               Drama|\n",
      "|     15|Cutthroat Island ...|Action|Adventure|...|\n",
      "|     16|       Casino (1995)|         Crime|Drama|\n",
      "|     17|Sense and Sensibi...|       Drama|Romance|\n",
      "|     18|   Four Rooms (1995)|              Comedy|\n",
      "|     19|Ace Ventura: When...|              Comedy|\n",
      "|     20|  Money Train (1995)|Action|Comedy|Cri...|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Movies_df.printSchema()\n",
    "Movies_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n",
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "|     1|      6|   4.0|964982224|\n",
      "|     1|     47|   5.0|964983815|\n",
      "|     1|     50|   5.0|964982931|\n",
      "|     1|     70|   3.0|964982400|\n",
      "|     1|    101|   5.0|964980868|\n",
      "|     1|    110|   4.0|964982176|\n",
      "|     1|    151|   5.0|964984041|\n",
      "|     1|    157|   5.0|964984100|\n",
      "|     1|    163|   5.0|964983650|\n",
      "|     1|    216|   5.0|964981208|\n",
      "|     1|    223|   3.0|964980985|\n",
      "|     1|    231|   5.0|964981179|\n",
      "|     1|    235|   4.0|964980908|\n",
      "|     1|    260|   5.0|964981680|\n",
      "|     1|    296|   3.0|964982967|\n",
      "|     1|    316|   3.0|964982310|\n",
      "|     1|    333|   5.0|964981179|\n",
      "|     1|    349|   4.0|964982563|\n",
      "+------+-------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Ratings_df.printSchema()\n",
    "Ratings_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing data types and eliminating the timestamp column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Ratings_df=Ratings_df.withColumn('rating', Ratings_df['rating'].cast(\"float\"))\n",
    "Ratings_df=Ratings_df.withColumn('userId', Ratings_df['userId'].cast(\"integer\"))\n",
    "Ratings_df=Ratings_df.withColumn('movieId', Ratings_df['movieId'].cast(\"integer\"))\n",
    "Ratings_df = Ratings_df.drop(*['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      "\n",
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|      1|   4.0|\n",
      "|     1|      3|   4.0|\n",
      "|     1|      6|   4.0|\n",
      "|     1|     47|   5.0|\n",
      "|     1|     50|   5.0|\n",
      "|     1|     70|   3.0|\n",
      "|     1|    101|   5.0|\n",
      "|     1|    110|   4.0|\n",
      "|     1|    151|   5.0|\n",
      "|     1|    157|   5.0|\n",
      "|     1|    163|   5.0|\n",
      "|     1|    216|   5.0|\n",
      "|     1|    223|   3.0|\n",
      "|     1|    231|   5.0|\n",
      "|     1|    235|   4.0|\n",
      "|     1|    260|   5.0|\n",
      "|     1|    296|   3.0|\n",
      "|     1|    316|   3.0|\n",
      "|     1|    333|   5.0|\n",
      "|     1|    349|   4.0|\n",
      "+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Ratings_df.printSchema()\n",
    "Ratings_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the distribution of the dataset by user and by movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|userId|count|\n",
      "+------+-----+\n",
      "|   148|   48|\n",
      "|   463|   33|\n",
      "|   471|   28|\n",
      "|   496|   29|\n",
      "|   243|   36|\n",
      "|   392|   25|\n",
      "|   540|   42|\n",
      "|    31|   50|\n",
      "|   516|   26|\n",
      "|    85|   34|\n",
      "|   137|  141|\n",
      "|   251|   23|\n",
      "|   451|   34|\n",
      "|   580|  436|\n",
      "|    65|   34|\n",
      "|   458|   59|\n",
      "|    53|   20|\n",
      "|   255|   44|\n",
      "|   481|   31|\n",
      "|   588|   56|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_ratings = Ratings_df.groupBy(\"userId\").count()\n",
    "user_ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|movieId|count|\n",
      "+-------+-----+\n",
      "|   1580|  165|\n",
      "|   2366|   25|\n",
      "|   3175|   75|\n",
      "|   1088|   42|\n",
      "|  32460|    4|\n",
      "|  44022|   23|\n",
      "|  96488|    4|\n",
      "|   1238|    9|\n",
      "|   1342|   11|\n",
      "|   1591|   26|\n",
      "|   1645|   51|\n",
      "|   4519|    9|\n",
      "|   2142|   10|\n",
      "|    471|   40|\n",
      "|   3997|   12|\n",
      "|    833|    6|\n",
      "|   3918|    9|\n",
      "|   7982|    4|\n",
      "|   1959|   15|\n",
      "|  68135|   10|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_ratings = Ratings_df.groupBy(\"movieId\").count()\n",
    "movie_ratings.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to validate the obtained results, we need to separate the dataset into a train and test dataset, so, 90% of the data will be used to train and 10% to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create test and train set\n",
    "(Train, Test) = Ratings_df.randomSplit([0.9, 0.1], seed = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|      1|   4.0|\n",
      "|     1|      3|   4.0|\n",
      "|     1|      6|   4.0|\n",
      "|     1|     47|   5.0|\n",
      "|     1|     50|   5.0|\n",
      "|     1|     70|   3.0|\n",
      "|     1|    101|   5.0|\n",
      "|     1|    110|   4.0|\n",
      "|     1|    151|   5.0|\n",
      "|     1|    157|   5.0|\n",
      "|     1|    163|   5.0|\n",
      "|     1|    216|   5.0|\n",
      "|     1|    223|   3.0|\n",
      "|     1|    231|   5.0|\n",
      "|     1|    235|   4.0|\n",
      "|     1|    260|   5.0|\n",
      "|     1|    296|   3.0|\n",
      "|     1|    316|   3.0|\n",
      "|     1|    333|   5.0|\n",
      "|     1|    349|   4.0|\n",
      "+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Train_user_ratings = Train.groupBy(\"userId\").count()\n",
    "Train_users=Train_user_ratings.count()\n",
    "Train_user_ratings=Train_user_ratings.select('userId').rdd.map(lambda x: x[0]).collect()\n",
    "print(Train_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 610 different users in the Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597\n"
     ]
    }
   ],
   "source": [
    "Test_user_ratings = Test.groupBy(\"userId\").count()\n",
    "Test_users=Test_user_ratings.count() \n",
    "Test_user_ratings=Test_user_ratings.select('userId').rdd.map(lambda x: x[0]).collect()\n",
    "print(Test_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 597 different users in the Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9368\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Train_movie_ratings = Train.groupBy(\"movieID\").count()\n",
    "Train_movie=Train_movie_ratings.count()\n",
    "Train_movie_ratings=Train_movie_ratings.select('movieID').rdd.map(lambda x: x[0]).collect()\n",
    "print(Train_movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 9368 different movies in the Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3646\n"
     ]
    }
   ],
   "source": [
    "Test_movie_ratings = Test.groupBy(\"movieID\").count()\n",
    "Test_movie=Test_movie_ratings.count()\n",
    "Test_movie_ratings=Test_movie_ratings.select('movieID').rdd.map(lambda x: x[0]).collect()\n",
    "print(Test_movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3646 different movies in the Test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's possible that the train test split obtained has unique users and/or unique movies.\n",
    "\n",
    "This is problematic when comes the moment to compare the real results with predicted scores, so we need to check that with the NotUnique function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to check if the Test df doesn't have new users or new movies that aren't in the Train set\n",
    "\n",
    "def NotUnique(TrainList,TestList):\n",
    "    \n",
    "    for item in TestList:\n",
    "        if item not in TrainList:\n",
    "            print('This Train Test Split is not perfect (a part of the test Dataset will have to be ignored)')\n",
    "            return\n",
    "    print('This Train Test Split is perfect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Train Test Split is perfect\n",
      "This Train Test Split is not perfect (a part of the test Dataset will have to be ignored)\n"
     ]
    }
   ],
   "source": [
    "# Check for users\n",
    "NotUnique(Train_user_ratings,Test_user_ratings)\n",
    "# Check for movies\n",
    "NotUnique(Train_movie_ratings,Test_movie_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysing the output of the function, we conclude that the test dataset doesn't have unique users, however, it has unique movies. These movie ratings will have to be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing User Item Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will construct the user item matrix in two different ways, one based on movies, to get the similaritys between movies, and one based on users, to predict new scores.\n",
    "\n",
    "For this we need two costum made functions: transformRating and RatingJunction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transform rating function creates a rdd entry for each rating, were, in the index of a specific movie/user, puts the desired rating, and the rest of the rating list will have Nones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def transformRating(Id_1,rating,Id_2,items):\n",
    "    rating_list = [rating if ele == Id_1 else None for ele in items]\n",
    "    return ([Id_2]+[rating_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RatingJunction function combines all the ratings of a specific movie/user in a unique RDD entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def RatingJunction(a,b):\n",
    "\n",
    "    \n",
    "    n=0\n",
    "    for ind in b:   #Here I didn't run the whole list but only up to the index of b, this works because b is always an RDD with only one entry. Helps reduce computing time\n",
    "        if ind != None:\n",
    "            break\n",
    "        n=n+1\n",
    "\n",
    "    c=a\n",
    "    c[n]=b[n]\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDD Based on Users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a ordered list of movies (it'ś the order of the ratings in the user based RDD that will be made)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9368\n"
     ]
    }
   ],
   "source": [
    "# This List has all of the movies in the dataset, in the order that will appear in the Train_user_RDD\n",
    "items_movies = Train.select('movieId').rdd.map(lambda data:data.movieId).collect()\n",
    "items_movies = list(dict.fromkeys(items_movies))\n",
    "item_movies_len = len(items_movies)\n",
    "print(item_movies_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the user based RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Train_user_RDD =Train.rdd.map(lambda data:(data.movieId,data.rating,data.userId))\n",
    "\n",
    "Train_user_RDD=Train_user_RDD.map((lambda data:transformRating(data[0],data[1],data[2],items_movies)))\n",
    "\n",
    "Train_user_RDD=Train_user_RDD.map(lambda item: (item[0],item[1]))\n",
    "\n",
    "Train_user_RDD.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Train_user_RDD=Train_user_RDD.reduceByKey(lambda data_1,data_2:RatingJunction(data_1,data_2))\n",
    "\n",
    "Train_user_RDD.take(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_user_to_show shows us the item user RDD in a understandable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| _1|                  _2|\n",
      "+---+--------------------+\n",
      "|  1|[4.0, 4.0, 4.0, 5...|\n",
      "|  2|[null, null, null...|\n",
      "|  3|[null, null, null...|\n",
      "|  4|[null, null, null...|\n",
      "|  5|[4.0, null, null,...|\n",
      "|  6|[null, 5.0, null,...|\n",
      "|  7|[4.5, null, null,...|\n",
      "|  8|[null, null, null...|\n",
      "|  9|[null, null, null...|\n",
      "| 10|[null, null, null...|\n",
      "| 11|[null, null, null...|\n",
      "| 12|[null, null, null...|\n",
      "| 13|[null, null, null...|\n",
      "| 14|[null, null, null...|\n",
      "| 15|[2.5, null, null,...|\n",
      "| 16|[null, null, null...|\n",
      "| 17|[4.5, null, null,...|\n",
      "| 18|[3.5, null, 4.0, ...|\n",
      "| 19|[4.0, 3.0, null, ...|\n",
      "| 20|[null, null, null...|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_user_to_show=Train_user_RDD.toDF()\n",
    "\n",
    "df_user_to_show.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDD Based on Items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a ordered list of users (it'ś the order of the ratings in the movie based RDD that will be made)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610\n"
     ]
    }
   ],
   "source": [
    "# This List has all of the users in the dataset, in the order that will appear in the Train_movie_RDD\n",
    "items_users = Train.select('userId').rdd.map(lambda data:data.userId).collect()\n",
    "items_users = list(dict.fromkeys(items_users))\n",
    "item_users_len = len(items_users)\n",
    "print(item_users_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the movie based RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Train_movie_RDD =Train.rdd.map(lambda data:(data.userId,data.rating,data.movieId))\n",
    "\n",
    "Train_movie_RDD=Train_movie_RDD.map((lambda data:transformRating(data[0],data[1],data[2],items_users)))\n",
    "\n",
    "Train_movie_RDD=Train_movie_RDD.map(lambda item: (item[0],item[1]))\n",
    "\n",
    "Train_movie_RDD.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Train_movie_RDD=Train_movie_RDD.reduceByKey(lambda data_1,data_2:RatingJunction(data_1,data_2))\n",
    "\n",
    "Train_movie_RDD.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_movie_to_show shows us the item user RDD in a understandable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| _1|                  _2|\n",
      "+---+--------------------+\n",
      "|  1|[4.0, null, null,...|\n",
      "|  3|[4.0, null, null,...|\n",
      "|  6|[4.0, null, null,...|\n",
      "| 47|[5.0, null, null,...|\n",
      "| 50|[5.0, null, null,...|\n",
      "| 70|[3.0, null, null,...|\n",
      "|101|[5.0, null, null,...|\n",
      "|110|[4.0, null, null,...|\n",
      "|151|[5.0, null, null,...|\n",
      "|157|[5.0, null, null,...|\n",
      "|163|[5.0, null, null,...|\n",
      "|216|[5.0, null, null,...|\n",
      "|223|[3.0, null, null,...|\n",
      "|231|[5.0, null, null,...|\n",
      "|235|[4.0, null, null,...|\n",
      "|260|[5.0, null, null,...|\n",
      "|296|[3.0, null, null,...|\n",
      "|316|[3.0, null, null,...|\n",
      "|333|[5.0, 4.0, null, ...|\n",
      "|349|[4.0, null, null,...|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_movie=Train_movie_RDD.toDF()\n",
    "\n",
    "df_movie.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get similaritys between Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to obtain the similaritys between movies is to subtract the mean rating of a movie to each of it's ratings. Non existing ratings will be substituted with 0.\n",
    "\n",
    "This is obtained with the Pearson_step1 function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Pearson_step1(item):\n",
    "    ratings=item[1]\n",
    "    ratings_Ex = list(filter(None,ratings))\n",
    "    mean=sum(ratings_Ex)/len(ratings_Ex)\n",
    "    n=0\n",
    "    for rat in ratings:\n",
    "        if rat != None:\n",
    "            ratings[n]=ratings[n]-mean\n",
    "        else:\n",
    "            ratings[n]=0.0\n",
    "        n=n+1\n",
    "    return (item[0], ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Similarity_RDD = Train_movie_RDD.map(lambda item: Pearson_step1(item))\n",
    "\n",
    "Similarity_RDD.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn the similarity RDD into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| _1|                  _2|\n",
      "+---+--------------------+\n",
      "|  1|[0.06578947368421...|\n",
      "|  3|[0.72340425531914...|\n",
      "|  6|[0.09890109890109...|\n",
      "| 47|[1.04278074866310...|\n",
      "| 50|[0.78378378378378...|\n",
      "| 70|[-0.5098039215686...|\n",
      "|101|[1.19047619047619...|\n",
      "|110|[-0.0539215686274...|\n",
      "|151|[1.37837837837837...|\n",
      "|157|[2.05, 0.0, 0.0, ...|\n",
      "|163|[1.44067796610169...|\n",
      "|216|[1.59756097560975...|\n",
      "|223|[-0.8370786516853...|\n",
      "|231|[1.86885245901639...|\n",
      "|235|[0.40163934426229...|\n",
      "|260|[0.80786026200873...|\n",
      "|296|[-1.1845878136200...|\n",
      "|316|[-0.3849206349206...|\n",
      "|333|[1.13095238095238...|\n",
      "|349|[0.40291262135922...|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_movie_s=Similarity_RDD.toDF()\n",
    "\n",
    "df_movie_s.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do a crossJoin on the Dataframe, too facilitate the process to obtain similarities. Each row will be used to get different similarities between movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+---------+--------------------+\n",
      "|movieId_1|           ratings_1|movieId_2|           ratings_2|\n",
      "+---------+--------------------+---------+--------------------+\n",
      "|        1|[0.06578947368421...|        1|[0.06578947368421...|\n",
      "|        1|[0.06578947368421...|        3|[0.72340425531914...|\n",
      "|        1|[0.06578947368421...|        6|[0.09890109890109...|\n",
      "|        1|[0.06578947368421...|       47|[1.04278074866310...|\n",
      "|        1|[0.06578947368421...|       50|[0.78378378378378...|\n",
      "|        1|[0.06578947368421...|       70|[-0.5098039215686...|\n",
      "|        1|[0.06578947368421...|      101|[1.19047619047619...|\n",
      "|        1|[0.06578947368421...|      110|[-0.0539215686274...|\n",
      "|        1|[0.06578947368421...|      151|[1.37837837837837...|\n",
      "|        1|[0.06578947368421...|      157|[2.05, 0.0, 0.0, ...|\n",
      "|        1|[0.06578947368421...|      163|[1.44067796610169...|\n",
      "|        1|[0.06578947368421...|      216|[1.59756097560975...|\n",
      "|        1|[0.06578947368421...|      223|[-0.8370786516853...|\n",
      "|        1|[0.06578947368421...|      231|[1.86885245901639...|\n",
      "|        1|[0.06578947368421...|      235|[0.40163934426229...|\n",
      "|        1|[0.06578947368421...|      260|[0.80786026200873...|\n",
      "|        1|[0.06578947368421...|      296|[-1.1845878136200...|\n",
      "|        1|[0.06578947368421...|      316|[-0.3849206349206...|\n",
      "|        1|[0.06578947368421...|      333|[1.13095238095238...|\n",
      "|        1|[0.06578947368421...|      349|[0.40291262135922...|\n",
      "+---------+--------------------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Join DFs\n",
    "df_join = df_movie_s.crossJoin(df_movie_s.select('_1', F.col(\"_2\").alias(\"ratings_2\")))\n",
    "\n",
    "Data_list = [\"movieId_1\",\"ratings_1\",\"movieId_2\",\"ratings_2\"]\n",
    " \n",
    "df_join = df_join.toDF(*Data_list)\n",
    "\n",
    "df_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "JoinedRDD= df_join.rdd.map(lambda x: ((x.movieId_1,x.movieId_2),x.ratings_1,x.ratings_2))\n",
    "\n",
    "JoinedRDD.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The funtion cosine_sim calculates the cosine similarity between lists of ratings. After applying it we obtain the similarities between movies.\n",
    "\n",
    "In the function we sum the multiplication of the ratings of a movie \"i\" and \"j\" given by all users. Then divide this with a multiplication of square roots of the sum of squared ratings of the movie \"i\" and \"j\" by users.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cosine_sim(item):\n",
    "    rating_1=item[1]\n",
    "    rating_2=item[2]\n",
    "\n",
    "    #prod is the dividend of cosine similarity\n",
    "    prod_list=[]\n",
    "    for n in range(0,item_users_len):\n",
    "        number=rating_1[n]*rating_2[n]\n",
    "        prod_list.append(number)\n",
    "    prod=sum(prod_list)\n",
    "\n",
    "    #prod2 is the divider of cosine similarity\n",
    "    square_1=sqrt(sum([ x**2 for x in rating_1 ]))\n",
    "    square_2=sqrt(sum([ x**2 for x in rating_2 ]))\n",
    "\n",
    "    prod2=square_1*square_2\n",
    "\n",
    "    # if prod2 is 0, we can't use it as the divider, so we change it to a very small number\n",
    "    if prod2==0:\n",
    "        prod2=0.000000000000000001\n",
    "\n",
    "    similarity=prod/prod2\n",
    "\n",
    "    return (item[0],similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[((1, 1), 1.0000000000000002),\n",
       " ((1, 3), 0.10202629136285349),\n",
       " ((1, 6), 0.05443336831241767)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarityRDD=JoinedRDD.map(lambda data: cosine_sim(data))\n",
    "\n",
    "similarityRDD.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now similarityRDD is a RDD with a tuple of the 2 movies and their similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce computation time and to eliminate low similarities, that, probably, would lead to bad predictions, we filter the similarities. We are going to use just movie similarities bigger than 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation values smaller than 0.30 are considered weak\n",
    "similarity_filter_RDD=similarityRDD.filter(lambda x: x[1]>0.30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get movies : rating dictionary, it will be used to predict scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# This dictionary has all of the meaningfull similarities between movies, the similarities are duplicated (each similarity appears 2 times, but with the items displaied in a different order)\n",
    "\n",
    "Similarity_Dict=similarity_filter_RDD.collectAsMap()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Similarity_Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get scores for non rated movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores function predicts scores to non rated movies by the users. \n",
    "\n",
    "First, for every movie \"i\" non rated by a user, we calculate the 10 biggest similarites that this movie has, and, at the same time, that the user as rated.\n",
    "\n",
    "Then, we divide the sum of these similarities times the rating given by the user with the sum of similarities. In this way, we get the predicted score for that movie.\n",
    "\n",
    "Movies that were already rated by users will be represented in the predictions matrix as -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(item):\n",
    "    \n",
    "    user=item[0]\n",
    "    ratings_change=item[1]\n",
    "    ratings_non_change=ratings_change[:]\n",
    "    \n",
    "    for n in range(0,item_movies_len):\n",
    "        \n",
    "        if ratings_change[n]==None:\n",
    "            \n",
    "            i=items_movies[n]            \n",
    "            i_dict = {}\n",
    "            \n",
    "            # i_dict is going to be a list with top 10 similaritys with movie i, that the user saw\n",
    "            for item, value in Similarity_Dict.items():\n",
    "                if (item[0] == i) and ratings_non_change[items_movies.index(item[1])]!=None:\n",
    "                    i_dict[item] = (value, ratings_non_change[items_movies.index(item[1])])                 \n",
    "            i_dict = sorted(i_dict.items(), key=lambda x:-x[1][0])[:10]           \n",
    "            \n",
    "            # calculate score\n",
    "            term1=0\n",
    "            term2=0\n",
    "            for item, value in i_dict:\n",
    "                term1=term1+(value[0]*value[1])\n",
    "                term2=term2+value[0]\n",
    "\n",
    "            #if the divider is 0, we have to change it to a very small number to continue the calculations    \n",
    "            if term2==0:\n",
    "                term2=0.0000000000000000001\n",
    "                \n",
    "            score=term1/term2\n",
    "            ratings_change[n]=score\n",
    "            \n",
    "        else:\n",
    "            ratings_change[n]=-1\n",
    "            \n",
    "    return (user,ratings_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "ScoresRDD=Train_user_RDD.map(lambda data: scores(data))\n",
    "\n",
    "ScoresRDD.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the ScoresRDD is a RDD with the predicted scores, scores represented by 0 are movies that, for the user in question, the algorithm didn't foud similarities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have the predicted scores for all the users, we can choose the users we want to check the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we will check the predictions for 10 users, we can choose the users we want to check by changing the userId values present in the User_Check list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change here the users you want to check\n",
    "\n",
    "User_Check = [1,2,3,4,5,6,7,8,9,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RDD with just the users we want to check\n",
    "\n",
    "User_Scores_RDD=ScoresRDD.filter(lambda x: x[0] in User_Check)\n",
    "\n",
    "User_Scores_RDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 83:>                 (0 + 1) / 1][Stage 85:>                 (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "User_Scores = User_Scores_RDD.take(len(User_Check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "User_Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movies_Code_Dict is going to be a dictionary that correlates the code of a movie with it's name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 83:>                 (0 + 1) / 1][Stage 85:>                 (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "# Create Dictionary Movie Code:Movie Name\n",
    "\n",
    "Movies_df=Movies_df.drop(*['genres'])\n",
    "\n",
    "Movies_CodeRDD = Movies_df.rdd.map(tuple)\n",
    "\n",
    "Movies_Code_Dict=Movies_CodeRDD.collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "Movies_Code_Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get the results for the chosen users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some movies with highest recomendation to user:  1\n",
      "Wolf of Wall Street, The (2013) | Interstellar (2014) | Whiplash (2014) | Dangerous Minds (1995) | Courage Under Fire (1996) | Operation Dumbo Drop (1995) | Wallace & Gromit: The Best of Aardman Animation (1996) | Doors, The (1991) | On Golden Pond (1981) | Deer Hunter, The (1978) | Patton (1970) | Field of Dreams (1989) | Lady and the Tramp (1955) | Saturn 3 (1980) | Fast Times at Ridgemont High (1982) | The Lair of the White Worm (1988) | Snow Dogs (2002) | Green Card (1990) | Death Race 2000 (1975) | Mighty Aphrodite (1995) | Muriel's Wedding (1994) | More  1061  movies.\n",
      "\n",
      "\n",
      "Some movies with highest recomendation to user:  2\n",
      "Flight of the Navigator (1986) | Troll 2 (1990) | Before Sunrise (1995) | Ocean's Eleven (2001) | Man on Fire (2004) | National Treasure (2004) | Phantom of the Opera, The (2004) | Girl with a Pearl Earring (2003) | Hotel Rwanda (2004) | Quantum of Solace (2008) | He's Just Not That Into You (2009) | Kung Fu Panda 2 (2011) | Help, The (2011) | Ice Age 4: Continental Drift (2012) | Skyfall (2012) | Despicable Me 2 (2013) | Enough Said (2013) | Notebook, The (2004) | The Butterfly Effect (2004) | Iron Man (2008) | Gran Torino (2008) | More  167  movies.\n",
      "\n",
      "\n",
      "Some movies with highest recomendation to user:  3\n",
      "Adventures of Robin Hood, The (1938) | Logan's Run (1976) | Superman (1978) | Predator (1987) | Step Brothers (2008) | High Plains Drifter (1973) | Balto (1995) | Feeling Minnesota (1996) | Miss Congeniality 2: Armed and Fabulous (2005) | King of Comedy, The (1983) | Easy A (2010) | Best Exotic Marigold Hotel, The (2011) | Barefoot (2014) | The Second Best Exotic Marigold Hotel (2015) | Chappie (2015) | 10 Cloverfield Lane (2016) | Once Upon a Time in the West (C'era una volta il West) (1968) | Way of the Gun, The (2000) | Crimson Rivers, The (Rivières pourpres, Les) (2000) | Layer Cake (2004) | Aeon Flux (2005) | More  396  movies.\n",
      "\n",
      "\n",
      "Some movies with highest recomendation to user:  4\n",
      "Jurassic Park (1993) | Star Wars: Episode VI - Return of the Jedi (1983) | Blues Brothers, The (1980) | Bambi (1942) | Negotiator, The (1998) | Song of the South (1946) | Very Bad Things (1998) | Psycho (1998) | Big (1988) | Mad Max (1979) | Inside Job (2010) | In the Line of Fire (1993) | Secret Garden, The (1993) | American President, The (1995) | Othello (1995) | Eye for an Eye (1996) | Juror, The (1996) | Lord of Illusions (1995) | Something to Talk About (1995) | Major Payne (1995) | Love Affair (1994) | More  702  movies.\n",
      "\n",
      "\n",
      "Some movies with highest recomendation to user:  5\n",
      "Sword in the Stone, The (1963) | Alice in Wonderland (1951) | Quiet Man, The (1952) | Bambi (1942) | Night on Earth (1991) | Pecker (1998) | Crimes and Misdemeanors (1989) | Together (Tillsammans) (2000) | Man Who Wasn't There, The (2001) | Passengers (2016) | Cinderella (1950) | Peter Pan (1953) | Rescuers Down Under, The (1990) | Sandlot, The (1993) | Jackass: The Movie (2002) | Rosencrantz and Guildenstern Are Dead (1990) | Bronx Tale, A (1993) | King of New York (1990) | The Falcon and the Snowman (1985) | Croupier (1998) | Reversal of Fortune (1990) | More  43  movies.\n",
      "\n",
      "\n",
      "Some movies with highest recomendation to user:  6\n",
      "Toy Story (1995) | Rock, The (1996) | Newton Boys, The (1998) | Lethal Weapon (1987) | Howard the Duck (1986) | Grumpy Old Men (1993) | Space Cowboys (2000) | Picture Perfect (1997) | Memphis Belle (1990) | Identity (2003) | 127 Hours (2010) | Peter Pan (2003) | Black Sheep (2006) | \n",
      "\n",
      "Some movies with highest recomendation to user:  7\n",
      "Blown Away (1994) | Fugitive, The (1993) | Swingers (1996) | Duck Soup (1933) | Fantasia (1940) | Nosferatu (Nosferatu, eine Symphonie des Grauens) (1922) | McHale's Navy (1997) | Conan the Barbarian (1982) | Lethal Weapon (1987) | Saving Private Ryan (1998) | Legend (1985) | Dr. No (1962) | Fight Club (1999) | Ladyhawke (1985) | Django Unchained (2012) | Wolf of Wall Street, The (2013) | Interstellar (2014) | Whiplash (2014) | Adventures of Priscilla, Queen of the Desert, The (1994) | Pajama Game, The (1957) | State and Main (2000) | More  367  movies.\n",
      "\n",
      "\n",
      "Some movies with highest recomendation to user:  8\n",
      "Clerks (1994) | Client, The (1994) | \n",
      "\n",
      "Some movies with highest recomendation to user:  9\n",
      "Star Wars: Episode V - The Empire Strikes Back (1980) | Big (1988) | Shutter Island (2010) | Indiana Jones and the Last Crusade (1989) | Lord of the Rings: The Return of the King, The (2003) | Trainspotting (1996) | The Machinist (2004) | Transformers (2007) | Hanna (2011) | Drive (2011) | From Hell (2001) | American Hustle (2013) | Avengers: Age of Ultron (2015) | Shopgirl (2005) | Tomb Raider (2018) | Nothing to Lose (1997) | Down with Love (2003) | Ladykillers, The (2004) | Boy in the Striped Pajamas, The (Boy in the Striped Pyjamas, The) (2008) | War for the Planet of the Apes (2017) | Simone (S1m0ne) (2002) | More  2  movies.\n",
      "\n",
      "\n",
      "Some movies with highest recomendation to user:  10\n",
      "Last of the Mohicans, The (1992) | Song of the South (1946) | Very Bad Things (1998) | Departed, The (2006) | Inside Job (2010) | Searchers, The (1956) | Othello (1995) | Eye for an Eye (1996) | Dunston Checks In (1996) | Nick of Time (1995) | Wild Bill (1995) | Heavyweights (Heavy Weights) (1995) | Love Affair (1994) | Man of the House (1995) | Cobb (1994) | I'll Do Anything (1994) | Little Big League (1994) | Angus (1995) | Quest, The (1996) | Chamber, The (1996) | Shrek 2 (2004) | More  296  movies.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 83:>                 (0 + 1) / 1][Stage 85:>                 (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "for item in User_Scores:\n",
    "    user=item[0]\n",
    "    print('Some movies with highest recomendation to user: ', user)\n",
    "    ratings=item[1]\n",
    "    n=0\n",
    "    recomended=[]\n",
    "    for rate in ratings:\n",
    "        if rate>=4.5:  #Change here the threshold of score you want to analyse\n",
    "            recomended.append(Movies_Code_Dict[str(items_movies[n])])\n",
    "        n=n+1\n",
    "    m=0\n",
    "    for movie in recomended:\n",
    "        if m>20:\n",
    "            print('More ', len(recomended)-20, ' movies.' )\n",
    "            break\n",
    "        print(movie, end = ' | ')   \n",
    "        m=m+1\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to validate our results, for this we use the test set, and compare the real values given by the users with the predicted values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we transform the test Dataset into a RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 362, 5.0), (1, 527, 5.0)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 83:>                 (0 + 1) / 1][Stage 85:>                 (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "\n",
    "Test_RDD =Test.rdd.map(lambda data:(data.userId, data.movieId, data.rating,))\n",
    "\n",
    "Test_RDD.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To validate the results we will just use the users we checked in the last section, so we can filter the Test_RDD with that in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_RDD=Test_RDD.filter(lambda x: x[0] in User_Check)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to compare the values, we need to collect the obtained results. row_scores is going to be a list with the predicted scores and user_ordered is going to be a list of users by the order encountered in the predicted scores list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ordered = [item[0] for item in User_Scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function PredictedScore finds the predicted score of a test rating in the row_scores list, if any score is found it returns Nones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictedScore(item):\n",
    "    \n",
    "    if item[0] in Train_user_ratings and item[1] in Train_movie_ratings:\n",
    "        user_index=user_ordered.index(item[0])\n",
    "        \n",
    "        predicted=User_Scores[user_index][1][items_movies.index(item[1])]                       \n",
    "\n",
    "        if predicted==0:\n",
    "            # In this case the algorithm wasn't able to discover a score, becase the similaritys between this movie and other movies are low.\n",
    "            return(None, None, None, None)\n",
    "    \n",
    "        return (item[0], item[1], item[2], predicted)\n",
    "    \n",
    "    # This rating ins't possible to get because the Train dataset dind't had the movie related to it \n",
    "    else:\n",
    "        return(None, None, None, None)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(None, None, None, None),\n",
       " (None, None, None, None),\n",
       " (None, None, None, None),\n",
       " (None, None, None, None)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 83:>                 (0 + 1) / 1][Stage 85:>                 (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "Test_RDD=Test_RDD.map(lambda data: PredictedScore(data))\n",
    "\n",
    "Test_RDD.take(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminating rows with Nones (the ones corresponding to non predicted ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 1009, 3.0, 5.0),\n",
       " (1, 1029, 5.0, 5.0),\n",
       " (1, 1080, 5.0, 5.0),\n",
       " (1, 1208, 4.0, 5.0)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 83:>                 (0 + 1) / 1][Stage 85:>                 (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "Test_RDD = Test_RDD.filter( lambda x: x[0]!=None)\n",
    "\n",
    "Test_RDD.take(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we we turn the Test_RDD into a DataFrame and get the following results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+------------------+\n",
      "|userId|movieId|rating|        prediction|\n",
      "+------+-------+------+------------------+\n",
      "|     1|   1009|   3.0|               5.0|\n",
      "|     1|   1029|   5.0|               5.0|\n",
      "|     1|   1080|   5.0|               5.0|\n",
      "|     1|   1208|   4.0|               5.0|\n",
      "|     1|   1291|   5.0|               5.0|\n",
      "|     1|   2012|   4.0| 4.082240035914576|\n",
      "|     1|   2048|   5.0|               5.0|\n",
      "|     1|   2094|   5.0|               5.0|\n",
      "|     1|   2406|   4.0|               5.0|\n",
      "|     1|   2648|   4.0|               5.0|\n",
      "|     1|   3034|   5.0|               5.0|\n",
      "|     4|    190|   2.0|               4.0|\n",
      "|     4|   1250|   5.0| 4.319585789296528|\n",
      "|     4|   1885|   3.0|3.6303145256930645|\n",
      "|     4|   2019|   2.0|               4.0|\n",
      "|     4|   2186|   5.0| 4.739947127994415|\n",
      "|     4|   4033|   4.0|          3.390625|\n",
      "|     4|   4144|   3.0|3.5971843056019686|\n",
      "|     6|      6|   4.0|               3.0|\n",
      "|     6|     36|   5.0|               4.0|\n",
      "+------+-------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 83:>                 (0 + 1) / 1][Stage 85:>                 (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "Test_predict = Test_RDD.toDF()\n",
    "\n",
    "Test_predict=Test_predict.toDF(*['userId','movieId','rating','prediction'])\n",
    "\n",
    "Test_predict.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyse if the results are similar to the real ratings, we use the RMSE algorithm (Root-mean-square error). It shows how the predicted rating, in mean, is different to the real rating.\n",
    "\n",
    "The RMSE algorithm is calculated in the following way: sum of the predicted rating minus the real rating squared, then divide it with the sum of the predicted ratings, finally square root the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1702033707556876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 83:>                 (0 + 1) / 1][Stage 85:>                 (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\") \n",
    "\n",
    "RMSE = evaluator.evaluate(Test_predict)\n",
    "print(RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obtained result, 1.17, is relatively good. It means that a predicted rating is, in mean, separeted from the real value by a score of 1.17. \n",
    "\n",
    "Although not perfect, is enough to obtain movies that the user will probably like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the Test_RDD to get the precision at top 10\n",
    "\n",
    "To calculate it, we take a threshold, in this case we chosed 3.5, that separates movies into to categories, the ones to recomend and the ones to not recomend. Then, we check if the real rating given by the user leads to the same result has the predicted rating (recomend or don't recomend), in the 10 movies with the biggest predicted rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leght of the predicted data:\n",
      "[(1, 10), (4, 6), (6, 8), (7, 3), (10, 6)]\n",
      "\n",
      "Top 10 algorithm by user:\n",
      "[(1, 0.9), (4, 0.3333333333333333), (6, 0.625), (7, 0.6666666666666666), (10, 0.8333333333333334)]\n",
      "\n",
      "Top 10 algorithm mean:\n",
      "0.6716666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 83:>                 (0 + 1) / 1][Stage 85:>                 (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "Top10_list=[]\n",
    "Top10_user_list=[]\n",
    "Top10_len_list=[]\n",
    "for userID in User_Check:\n",
    "\n",
    "    userID_RDD = Test_RDD.filter(lambda x: x[0]== userID)\n",
    "    userID_RDD = userID_RDD.filter(lambda x: x[3]>= 3.5)\n",
    "    userID_RDD = userID_RDD.map(lambda x: [x[2], x[3]])\n",
    "    userID_list = userID_RDD.collect()\n",
    "\n",
    "    if len(userID_list)>=1:\n",
    "        userID_list = sorted(userID_list, key=lambda x: x[1], reverse=True)\n",
    "        userID_list = userID_list[:10]\n",
    "        quantity=0\n",
    "        pred=0\n",
    "        for x in userID_list:\n",
    "            if x[0]>= 3.5: # defined threshold\n",
    "                pred = pred+1\n",
    "            quantity=quantity+1\n",
    "        Top10_list.append(pred/quantity)\n",
    "        Top10_user_list.append((userID,pred/quantity))\n",
    "        Top10_len_list.append((userID,len(userID_list)))\n",
    "\n",
    "\n",
    "print('Length of the predicted data:')\n",
    "print(Top10_len_list)\n",
    "\n",
    "print()\n",
    "\n",
    "print('Top 10 algorithm by user:')\n",
    "print(Top10_user_list)\n",
    "\n",
    "print()\n",
    "\n",
    "print('Top 10 algorithm mean:')\n",
    "Top10_mean=sum(Top10_list)/len(Top10_list)\n",
    "\n",
    "print(Top10_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best results we got were the ones of user 1, were 90% of the predictions were good predictions. The other users have lower percentage of good predictions.\n",
    "\n",
    "In the analysed users, the only user that has at least 10 ratings possible to compare is user 1, so the results obtained for the other users aren't a \"real\" top 10. This leads to some problems in the analysis of the other users, because some of the movies will have predicted ratings very close to the defined threshold.\n",
    "\n",
    "The Top 10 mean obtained is 0.67, it isn't bad having the above in mind."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "feadebf20b976b1cfb56aefc2c30fd72e4ba64937f7d4f9e81b2741d0d3f4dd7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
